import tensorflow as tf
import tensorflow_datasets as tfds

(ds_train, ds_test), ds_info = tfds.load(
    'fer2013',
    split=['train', 'test'],
    as_supervised=True,
    with_info=True
)
def preprocess(image, label):
    image = tf.image.resize(image, [48, 48])  # Resize images to 48x48
    image = tf.image.grayscale_to_rgb(image)  # Convert to RGB (if needed)
    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]
    return image, label

ds_train = ds_train.map(preprocess).batch(64).shuffle(1000)
ds_test = ds_test.map(preprocess).batch(64)
from tensorflow.keras import layers, models

def create_model():
    model = models.Sequential([
        layers.Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(256, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(7, activation='softmax')
    ])
    return model

model = create_model()
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])
history = model.fit(ds_train, epochs=30, validation_data=ds_test)
test_loss, test_acc = model.evaluate(ds_test)
print(f"Test accuracy: {test_acc}")
import cv2
import numpy as np

# Load the trained model
# model = tf.keras.models.load_model("path/to/your/saved_model")

cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break
    
    # Preprocess the frame
    face = cv2.resize(frame, (48, 48))
    face = face.astype("float32") / 255.0
    face = np.expand_dims(face, axis=0)
    
    # Predict the emotion
    predictions = model.predict(face)
    emotion_label = np.argmax(predictions[0])

    # Display the emotion on the screen
    cv2.putText(frame, f"Emotion: {emotion_label}", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.imshow("Facial Expression Recognition", frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
